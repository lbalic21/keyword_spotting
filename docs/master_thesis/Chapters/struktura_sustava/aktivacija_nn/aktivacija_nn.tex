\section{Aktivacija neuronske mreže}
\label{sec:activation}

Aktivacija neuronske mreže proces je u kojem se ulaznom sloju neuronske mreže 
(engl. \textit{input layer}) predaje matrica značajki generirana na način objašnjen u prethodnom
poglavlju. Biblioteka koja je korištena za implementaciju
neuronske mreže na mikrokontroleru je TensorFlow Lite \cite{tflm}. Omogućuje vrlo jednostavno
korištenje treniranog modela (treniranog na računalu kako je opisano u poglavlju
o treniranju neuronske mreže \ref{sec:training} te konvertiranog
u polje koje se može koristiti na mikrokontroleru kako je opisano u dijelu
o prilagodbi \ref{sec:convert}). Trenirani model
je polje 8-bitnih vrijednosti koje predstavljaju pojedine parametre mreže dobivene upravo 
treniranjem modela. Razred koji omotava korištenje biblioteke i modela prikazan je 
u isječku koda \ref{code:NeuralNetwork}. 
\newpage

\begin{lstlisting}[language=C++, caption=Razred neuronske mreže, label=code:NeuralNetwork]
class NeuralNetwork {
    private:
        const tflite::Model* model = nullptr;
        tflite::MicroMutableOpResolver<NUMBER_OF_OPERATORS> resolver;
        float* model_input_buffer = nullptr;
    public:
        NeuralNetwork();
        void giveFeaturesToModel(float* features, size_t numberOfFeatures);
        bool invoke(void);
        int numberOfClasses;
        float* outputData;  
};   
\end{lstlisting}

Članska varijabla \texttt{const tflite::Model* model} predstavlja 
pokazivač na polje parametara modela (koji ujedno sadrži i informacije o samoj strukturi mreže),
dok \texttt{tflite:: MicroMutableOpResolver<NUMBER\_OF\_OPERATORS> resolver}
predstavlja arhitekturu neuronske mreže koja koristi informacije iz polja parametara
modela kako bi pravilno procesirala dani ulaz. Toj strukturi je potrebno dodati sve vrste slojeva 
i funkcija koje se koriste unutar arhitekture mreže koja je trenirana. Primjer dodavanja 
nekih vrsta slojeva prikazan je u isječku koda \ref{code:resolver}. Nije bitan redoslijed 
dodavanja, samo je potrebno dodati sve što ta mreža sadrži. U suprotnom, inicijalizacija
modela neće uspjeti.

\begin{lstlisting}[language=C++, caption=Gradnja arhitekture mreže, label=code:resolver]
resolver.AddConv2D()            // konvolucijski sloj
resolver.AddFullyConnected()    // potpuno povezani sloj
resolver.AddSoftmax()           // softmax funkcija
resolver.AddMaxPool2D()         // sloj za poduzorkovanje
\end{lstlisting}

Nakon što je mreža alocirana na pravilan način (struktura polja u kojem se nalaze parametri
mreže odgovara strukturi mreže na mikrokontroleru) moguće joj je predati matricu značajki
te ju aktivirati. Nakon aktivacije, mreža obrađuje vrijednosti kroz svoju strukturu te na
izlazu daje vjerojatnosti da određeni ulaz (matrica značajki) predstavlja naučenu naredbu.
Kako je objašnjeno u \ref{sec:data}, broj kategorija za koje trenirana mreža daje na izlazu
vjerojatnosti je za dva veći od broja naredbi koje mreža može prepoznati. Dodatne kategorije
su "pozadina" (engl. \textit{background}) i "nepoznato" (engl. \textit{unknown}). 

Aktivacija neuronske mreže i dobivanje vrijednosti na njenom izlazu, koje predstavljaju
vjerojatnosti da ulazna matrica značajki pripada određenoj kategoriji, samo je jedna iteracija 
u radu sustava čija je struktura prikazana slikom \ref{pic:struktura_sustava}. Svakom novom 
iteracijom rada sustava prikupljaju se novi zvučni uzorci, matrica značajki se osvježava, 
tj. noviji MFC koeficijenti dolaze u matricu. Novi podaci u matrici predstavljaju značajke 
signala pomaknutog za dohvaćeni broj uzoraka (tipično 20-30 milisekundi) te je potrebno provjeriti
kojoj kategoriji pripada taj vremenski prozor. Budući da je od aktivacije mreže do izlaska 
rezultata u krajnjem sloju mreže potrebno određeno vrijeme, nije moguće aktivirati mrežu 
na svaki novi vremenski prozor podataka jer će biti zagušeno prikupljanje novih podataka
te cjelokupni sustav neće dobro raditi u stvarnom vremenu. Međutim, dobra strana postupka je da
nije potrebno aktivirati mrežu na svaki novi vremenski korak jer je svojom duljinom
puno manji od duljine uzorka kojeg predstavlja cijela matrica. Drugim riječima, uzastopne
verzije ulazne matrice podataka bit će vrlo slične i može se pričekati nekoliko novih
iteracija prije nego li se aktivira neuronska mreža (akviziranje signala i izdvajanje značajki
tipično traje puno kraće od aktivacije). S druge strane, mreža se mora aktivirati dovoljno
često jer u suprotnom postoji mogućnost propuštanja određenih naredbi. Parametar koji brine o tome 
koliko često se mreža aktivira zove se \texttt{NUMBER\_OF\_NEW\_SLICES\_BEFORE\_INVOKING} i određen
je eksperimentalno zbog toga što drugačije strukture mreže imaju drugačija vremena odziva.
Potrebno je maksimizirati broj aktiviranja mreže u određenom vremenu bez gubitaka
uzoraka ulaznog signala.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.4\linewidth]{Chapters/struktura_sustava/aktivacija_nn/timeline.png}
    \caption{Uzastopni vremenski okviri (prozori) \cite{flowchart}}
    \label{pic:timeline}
\end{figure}

Na slici \ref{pic:timeline} prikazani su uzastopni vremenski prozori nad ulaznim zvučnim signalom.
Na signalu je vidljiv vremenski odsječak u kojem je izgovorena naredba, a prije i poslije
izgovorene naredbe je tišina. U drugom i trećem prozoru očekuje se velika vjerojatnost da 
je prepoznata izgovorena naredba, dok se u prvom i četvrtom prozoru ne očekuje prepoznavanje
određene naredbe (u tim prozorima veću vjerojatnost imaju kategorije "nepoznato" ili "pozadina").
Upravo zbog prikazanog je potrebno što češće aktivirati mrežu i ne propustiti prepoznavanje naredbe. 
U slučaju da se mreža aktivira rjeđe, ne bi se prepoznala naredbu (npr. prvi pa četvrti
prozor). 

No, takav pristup otvara mjesto drugom problemu. Nije poželjno niti višestruko prepoznavanje
jednom izgovorene naredbe pa je stoga potreban podsustav za prepoznavanje i okidanje zadatka
povezanog s određenom naredbom.