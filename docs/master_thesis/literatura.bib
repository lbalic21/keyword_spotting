@misc{pycodemates,
  author =       {PyCodeMates, Sidharth},
  howpublished = {\url{https://www.pycodemates.com/2023/06/introduction-to-convolutional-neural-networks.html}},
  note =         {[Posjećeno: siječanj 2025.]},
}

@misc{indian,
  author =       {IndianTechWarrior},
  howpublished = {\url{https://indiantechwarrior.com/convolutional-neural-network-architecture/}},
  note =         {[Posjećeno: siječanj 2025.]},
}

@ARTICLE{1,
  author =      {Van Hiep Phung and Eun Joo Rhee},
  journal =     {Applied Sciences},
  title =       {A High-Accuracy Model Average Ensemble of Convolutional
                  Neural Networks for Classification of Cloud Image Patches on Small Datasets},
  year =        2019,
  volume =      9,
  number =      4500,
  abstract =    {Research on clouds has an enormous influence on sky sciences and related applications,
                  and cloud classification plays an essential role in it. Much research has been conducted which
                  includes both traditional machine learning approaches and deep learning approaches. Compared
                  with traditional machine learning approaches, deep learning approaches achieved better results.
                  However, most deep learning models need large data to train due to the large number of
                  parameters. Therefore, they cannot get high accuracy in case of small datasets. In this paper, we
                  propose a complete solution for high accuracy of classification of cloud image patches on small
                  datasets. Firstly, we designed a suitable convolutional neural network (CNN) model for small
                  datasets. Secondly, we applied regularization techniques to increase generalization and avoid
                  overfitting of the model. Finally, we introduce a model average ensemble to reduce the variance of
                  prediction and increase the classification accuracy. We experiment the proposed solution on the
                  Singapore whole-sky imaging categories (SWIMCAT) dataset, which demonstrates perfect
                  classification accuracy for most classes and confirms the robustness of the proposed model.},
  keywords =    {cloud classification; CNN; ensemble model; SWIMCAT dataset},
  doi =         {doi:10.3390/app9214500},
  url =         {https://doi.org/10.3390/app9214500}
}

@book{wardentinyml,
  author    = {Pete Warden and Daniel Situnayake},
  title     = {TinyML: Machine Learning with TensorFlow Lite on Arduino and Ultra-Low-Power Microcontrollers},
  publisher = {O'Reilly Media},
  year      = {2020},
  address   = {Sebastopol, CA},
  isbn      = {978-1492052043},
  url       = {https://www.oreilly.com/library/view/tinyml/9781492052036/},
}
@misc{activation_fcn,
  author = {V7 Labs},
  title = {Activation Functions in Neural Networks [12 Types and Use Cases]},
  year = 2021,
  howpublished = {\url{https://www.v7labs.com/blog/neural-networks-activation-functions}},
  note = {Accessed: January 2025}
}
  
@misc{desc,
  author =       {Analyticsvidhya, Mbali Kalirane},
  title  =       {{Gradient Descent vs. Backpropagation: What's the Difference?}},
  year =         2023,
  howpublished = {\url{https://www.analyticsvidhya.com/blog/2023/01/gradient-descent-vs-backpropagation-whats-the-difference/}},
  note =         {[Posjećeno: siječanj 2025.]},
}

@misc{dense,
  author =       {Kevin Ezra, Benjamin QoChuk},
  title  =       {{Introduction to Neural Network}},
  howpublished = {\url{https://iq.opengenus.org/dense-layer-in-tensorflow/}},
  note =         {[Posjećeno: siječanj 2025.]},
}

@misc{fully_connected,
  author =       {Geeks for Geeks},
  year =         2024,
  title  =       {{What is Fully Connected Layer in Deep Learning?}},
  howpublished = {\url{https://www.geeksforgeeks.org/what-is-fully-connected-layer-in-deep-learning/}},
  note =         {[Posjećeno: siječanj 2025.]},
}

@misc{1d,
  author =       {Geeks for Geeks},
  year =         2024,
  title  =       {{What is a 1D Convolutional Layer in Deep Learning?}},
  howpublished = {\url{https://www.geeksforgeeks.org/what-is-a-1d-convolutional-layer-in-deep-learning/?ref=next_article}},
  note =         {[Posjećeno: siječanj 2025.]},
}

@misc{netron,
  author       = {Lutz Roeder},
  title        = {Netron: Visualizer for neural network, deep learning, and machine learning models},
  howpublished = {\url{https://github.com/lutzroeder/netron}},
  year         = {2025},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{tinyml,
  author       = {Kurtis Pykes},
  title        = {What is TinyML? An Introduction to Tiny Machine Learning},
  howpublished = {\url{https://www.datacamp.com/blog/what-is-tinyml-tiny-machine-learning}},
  year         = {2023},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{cnn_how,
  author       = {Jason Brownlee},
  title        = {How Do Convolutional Layers Work in Deep Learning Neural Networks?},
  howpublished = {\url{https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/}},
  year         = {2020},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{pooling,
  author       = {Jason Brownlee},
  title        = {A Gentle Introduction to Pooling Layers for Convolutional Neural Networks},
  howpublished = {\url{https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/}},
  year         = {2019},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{cnn_whatis,
  author       = {Swapna, Data Engineer},
  title        = {Convolutional Neural Networks, Deep Learning},
  howpublished = {\url{https://developersbreach.com/convolution-neural-network-deep-learning/}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{convolution,
  title        = {Apply a 2D Convolution Operation in PyTorch},
  year         = 2023,
  howpublished = {\url{https://www.geeksforgeeks.org/apply-a-2d-convolution-operation-in-pytorch/}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{keras_layers,
  title        = {TensorFlow Keras Conv2D},
  howpublished = {\url{https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@mastersthesis{gracan2020,
  author       = {Ela Gračan},
  title        = {Prepoznavanje uzoraka pomoću neuronskih mreža},
  school       = {Sveučilište u Zagrebu, Prirodoslovno-matematički fakultet, Matematički odsjek},
  year         = {2020},
  type         = {Diplomski rad},
  address      = {Zagreb, Hrvatska},
  url          = {https://urn.nsk.hr/urn:nbn:hr:217:771401},
  note         = {URN:NBN: urn:nbn:hr:217:771401}
}

@misc{relu,
  title        = {Rectified Linear Units (ReLU) in Deep Learning},
  howpublished = {\url{https://www.kaggle.com/code/dansbecker/rectified-linear-units-relu-in-deep-learning}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@article{pooling1,
  author       = {Muhamad Yani and Casi Setianingsih},
  title        = {Application of Transfer Learning Using Convolutional Neural Network Method for Early Detection of Terry's Nail},
  journal      = {Journal of Physics: Conference Series},
  volume       = {1201},
  number       = {1},
  pages        = {012052},
  year         = {2019},
  month        = {May},
  doi          = {10.1088/1742-6596/1201/1/012052},
  license      = {CC BY 3.0}
}

@misc{flatten,
  title        = {Convolutional Neural Networks (CNN): Step 3 - Flattening},
  howpublished = {\url{https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{snajder2023logreg,
  author       = {Jan Šnajder},
  title        = {Logistička regresija 2},
  year         = {2023},
  howpublished = {Strojno učenje 1, UNIZG FER, ak. god. 2022./2023., predavanja, v1.10},
  note         = {Sveučilište u Zagrebu, Fakultet elektrotehnike i računarstva}
}

@article{speechcommandsv2,
   author = { {Warden}, P.},
    title = "{Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition}",
  journal = {ArXiv e-prints},
  archivePrefix = "arXiv",
  eprint = {1804.03209},
  primaryClass = "cs.CL",
  keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
    year = 2018,
    month = apr,
    url = {https://arxiv.org/abs/1804.03209},
}

@misc{balic_keyword_spotting,
  author       = {Luka Balić},
  title        = {Keyword Spotting},
  year         = {2025},
  howpublished = {\url{https://github.com/lbalic21/keyword_spotting}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{noise,
  title        = {White Noise vs Pink Noise},
  howpublished = {\url{https://getsnooz.com/blogs/snoozweek/white-noise-vs-pink-noise}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{balance,
  title        = {Introduction to Balanced and Imbalanced Datasets in Machine Learning},
  howpublished = {\url{https://encord.com/blog/an-introduction-to-balanced-and-imbalanced-datasets-in-machine-learning/}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{flowchart,
  title        = {Diagram Maker},
  howpublished = {\url{https://app.diagrams.net/}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{ringbufferrr,
  title        = {FreeRTOS (Supplemental Features)},
  howpublished = {\url{https://docs.espressif.com/projects/esp-idf/en/stable/esp32/api-reference/system/freertos_additions.html#ring-buffers}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{lyrat,
  title        = {ESP32-LyraT V4.3 Getting Started Guide},
  howpublished = {\url{https://docs.espressif.com/projects/esp-adf/en/latest/design-guide/dev-boards/get-started-esp32-lyrat.html}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@manual{es8388,
  title        = {ES8388 Low Power Stereo Audio Codec with Integrated Headphone Amplifier},
  author       = {Everest Semiconductor},
  year         = {2025},
  url          = {http://www.everest-semi.com/pdf/ES8388%20DS.pdf},
  note         = {[Posjećeno: siječanj 2025.]}
}

@article{sidhu2024mfcc,
  author       = {Manjit Singh Sidhu and Nur Atiqah Abdul Latib and Kirandeep Kaur Sidhu},
  title        = {MFCC in audio signal processing for voice disorder: a review},
  journal      = {Multimedia Tools and Applications},
  year         = {2024},
  doi          = {10.1007/s11042-024-19253-11},
  url          = {https://www.researchgate.net/publication/380151317_MFCC_in_audio_signal_processing_for_voice_disorder_a_review},
  note         = {[Posjećeno: siječanj 2025.]}
}

@book{petrinovic2002,
  author       = {Davor Petrinović},
  title        = {Digitalna obrada govora},
  year         = {2002},
  address      = {Zagreb},
  institution  = {Fakultet elektrotehnike i računarstva, Zavod za elektroničke sustave i obradbu informacija},
  note         = {Interna zavodska skripta, 08. 02. 2002}
}

@article{emotion,
author = {Patnaik, Suprava},
year = {2022},
month = {09},
pages = {},
title = {Speech emotion recognition by using complex MFCC and deep sequential model},
volume = {82},
journal = {Multimedia Tools and Applications},
doi = {10.1007/s11042-022-13725-y}
}

@article{multiplier,
author = {Yang, Jingsen},
year = {2025},
month = {01},
pages = {},
title = {A Low-Power Keyword Spotting Chip with Multiplier-Free MFCC Feature Extractor},
journal = {IEICE Electronics Express},
doi = {10.1587/elex.22.20250008}
}

@article{vasilijevic2011perceptual,
  author       = {Antonio Vasilijević and Davor Petrinović},
  title        = {Perceptual Significance of Cepstral Distortion Measures in Digital Speech Processing},
  journal      = {Automatika: časopis za automatiku, mjerenje, elektroniku, računarstvo i komunikacije},
  volume       = {52},
  number       = {2},
  pages        = {132--146},
  year         = {2011},
  doi          = {https://hrcak.srce.hr/71297},
  note         = {Izvorni znanstveni članak},
  url          = {https://hrcak.srce.hr/71297},
  keywords     = {Aliasing, Digital speech processing, MFCC, Mel cepstrum, SD Measure, Speech recognition}
}

@misc{windowing,
  title        = {Window function},
  howpublished = {\url{https://en.wikipedia.org/wiki/Window_function}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{hann,
  title        = {Mel-frequency Cepstral Coefficients (MFCC) for Speech Recognition},
  howpublished = {\url{https://www.geeksforgeeks.org/mel-frequency-cepstral-coefficients-mfcc-for-speech-recognition/?ref=ml_lbp}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{fft,
  author       = {Reducible},
  title        = {The Fast Fourier Transform (FFT): Most Ingenious Algorithm Ever?},
  howpublished = {YouTube Video},
  url          = {https://www.youtube.com/watch?v=h7apO7q16V0&ab_channel=Reducible},
  note         = {[Posjećeno: siječanj 2025.]},
}

@misc{mel,
  title        = {Mel scale},
  howpublished = {\url{https://en.wikipedia.org/wiki/Mel_scale}},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{tflm,
  author       = "{TensorFlow}",
  title        = "{TensorFlow Lite for Microcontrollers (TFLM)}",
  url          = {https://github.com/tensorflow/tflite-micro},
  note         = {[Posjećeno: siječanj 2025.]}
}

@misc{keras_adam,
  title = {Adam Optimizer},
  author = {Keras Team},
  year = {2025},
  howpublished = {\url{https://keras.io/api/optimizers/adam/}},
  note = {Accessed: 2025-02-07}
}

@misc{quantization,
  author = {{MathWorks}},
  title = {Quantization},
  year = {2025},
  url = {https://www.mathworks.com/discovery/quantization.html#:~:text=Quantization%20is%20the%20process%20of,and%20range%20of%20a%20value.},
  note = {Accessed: Feb. 13, 2025}
}

@misc{flatbuffers_docs,
  author = {{Google}},
  title = {FlatBuffers Documentation},
  year = {2025},
  url = {https://flatbuffers.dev/},
  note = {Accessed: Feb. 13, 2025}
}

@article{triplet,
  author    = {Roman Vygon and Nikolay Mikhaylovskiy},
  title     = {Learning Efficient Representations for Keyword Spotting with Triplet Loss},
  journal   = {ArXiv},
  year      = {2021},
  volume    = {abs/XXXX.XXXXX},
  url       = {https://arxiv.org/abs/XXXX.XXXXX},
  note      = {Accessed: Feb. 13, 2025}
}

@inproceedings{res,
  author    = {Byeonggeun Kim and Simyung Chang and Jinkyu Lee and Dooyong Sung},
  title     = {Broadcasted Residual Learning for Efficient Keyword Spotting},
  booktitle = {Proceedings of Interspeech 2021},
  pages     = {4538--4542},
  year      = {2021},
  organization = {International Speech Communication Association},
  doi       = {10.21437/Interspeech.2021-383},
  url       = {https://www.isca-speech.org/archive/pdfs/interspeech_2021/kim21l_interspeech.pdf}
}

@inproceedings{waveformer,
  author    = {Moritz Scherer and Cristian Cioflan and Michele Magno and Luca Benini},
  title     = {Work in Progress: Linear Transformers for TinyML},
  booktitle = {Proceedings of the 2024 Design, Automation \& Test in Europe Conference \& Exhibition (DATE)},
  year      = {2024},
  pages     = {N/A},
  publisher = {IEEE},
  address   = {Valencia, Spain},
  doi       = {10.23919/DATE58400.2024.10546828},
  url       = {https://ieeexplore.ieee.org/document/10546828},
  note      = {Accessed: Feb. 13, 2025}
}

@article{zhang2017hello,
  title={Hello Edge: Keyword Spotting on Microcontrollers},
  author={Zhang, Yundong and Suda, Naveen and Lai, Liangzhen and Chandra, Vikas},
  journal={arXiv preprint arXiv:1711.07128},
  year={2017},
  url={https://arxiv.org/abs/1711.07128}
}

@misc{arm_kws,
  author    = {ARM Software},
  title     = {ML-KWS-for-MCU: Machine Learning-based Keyword Spotting for Microcontrollers},
  year      = {2024},
  url       = {https://github.com/ARM-software/ML-KWS-for-MCU},
  note      = {Accessed: Feb. 13, 2025}
}

@misc{tflmicrospeech,
  author    = {ARM Software},
  title     = {AVH-TFLmicrospeech: Arm Virtual Hardware for TensorFlow Lite Micro Speech},
  year      = {2024},
  url       = {https://github.com/ARM-software/AVH-TFLmicrospeech},
  note      = {Accessed: Feb. 13, 2025}
}
