# Keyword spotting system 
![ESP32-S3](https://img.shields.io/badge/Platform-ESP32--S3-blue) ![C++](https://img.shields.io/badge/Language-C++-red) ![Python](https://img.shields.io/badge/NeuralNetworkTraining-Python-yellow) ![Status](https://img.shields.io/badge/Status-Active-brightgreen)

## ğŸ“Œ Overview
Keyword spotting (KWS) system is a lightweight and efficient system designed for the ESP32-S3. It processes audio input, extracts MFCC features, and runs inference on a neural network to detect commands and trigger predefined actions.

## âœ¨ Features
-  **Efficient Audio Command Recognition**: Detects and executes commands based on neural network inference.
-  **Customizable Command Set**: Easily choose which words trigger actions.
-  **Easy addition of new action**: Attach new actions to specific word command.
-  **Optimized for ESP32-S3**: Lightweight and performant for embedded systems.
-  **Low-Latency Execution**: Immediate response upon detecting a valid command.

## ğŸ— Repository Structure
```
/
 â”œâ”€â”€ docs       # Masters thesis written on this theme
 â”‚
 â”œâ”€â”€ microcontroller/ kws    # ESP32-S3 implementation (C++)
 â”‚   â”œâ”€â”€ src/                # Source code for command recognition
 â”‚   â”œâ”€â”€ models/             # Deployed models for inference
 â”‚
 â”œâ”€â”€ neural_network/              # Training and evaluation of the CNN model (Python)
 â”‚   â”œâ”€â”€ models                   # Trained models
 â”‚   â”œâ”€â”€ kws_network.ipynb        # Jupyter notebook used for neural network model training
 â”‚
 â”œâ”€â”€ recordings_playroom      # testing facility
```

## ğŸ›  Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/your-username/your-repo.git
cd your-repo
```

### 2ï¸âƒ£ Install Dependencies
- **Neural Network (Python)**: Install dependencies in `neural_network/`
  ```sh
  cd neural_network
  pip install -r requirements.txt
  ```
- **Microcontroller (C++)**: Follow the ESP-IDF installation guide for ESP32-S3 [here](https://docs.espressif.com/projects/esp-idf/en/latest/esp32s3/get-started/index.html).

### 3ï¸âƒ£ Build & Flash to ESP32-S3
```sh
cd microcontroller
idf.py set-target esp32s3
idf.py build flash monitor
```

## ğŸš€ Neural Network Training (Python)

### ğŸ“Œ Overview
The neural network processes spectrograms of recorded audio and learns to classify them into predefined commands.

### ğŸ›  Dataset Preparation
Place your dataset in `dataset/`. Ensure it is structured correctly with labeled audio files.

### ğŸ”§ Training the Model
Run the following command to train the model:
```sh
python train.py --epochs 10 --batch_size 32
```

### ğŸ“¤ Model Export
After training, the model will be saved in `model/`. Convert it for ESP32 deployment using:
```sh
python export_model.py --model model/best_model.h5 --output model/tflite_model.tflite
```

## ğŸš€ Microcontroller Implementation (C++)

### ğŸ“Œ Overview
The microcontroller captures audio, extracts MFCC features, and runs inference using the trained CNN model.

### ğŸ›  Setup & Installation

#### 1ï¸âƒ£ Set Up ESP-IDF
Follow the [ESP-IDF installation guide](https://docs.espressif.com/projects/esp-idf/en/latest/esp32s3/get-started/index.html) to install the development environment.

#### 2ï¸âƒ£ Build & Flash Firmware
Navigate to the `microcontroller/` directory and run:
```sh
idf.py set-target esp32s3
idf.py build flash monitor
```

#### 3ï¸âƒ£ Deploy the Model
Copy the converted TFLite model (`tflite_model.tflite`) into `models/` before flashing.

### ğŸš€ Running Inference
The recognizer processes audio and detects commands in real-time. If a command's probability exceeds `ACTIVATION_THRESHOLD`, it triggers an action.

## ğŸ“„ TODOs & Improvements
- [ ] Improve dataset preprocessing
- [ ] Optimize inference speed
- [ ] Experiment with different CNN architectures
- [ ] Implement a dynamic threshold for improved accuracy

## ğŸ“œ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
